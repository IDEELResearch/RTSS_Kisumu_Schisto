---
title: "Luminex Xponent: Plate- level Quality Control"
author: "Sahal Thahir & Jeff Bailey"
date: "2024-04-04"
params:
  input_file: "data/raw/luminex/example.csv"  # Input file path, all files in this folder will be analys
  min_beadcount: 50  # Minimum bead count for well bead QC
  min_Rsquared: 0.90 # Minimum R-squared for passing standard curve QC
  file_path: "data/qc"  # Output filepath for plate level plots and pdfs
output:
  pdf_document: default
---
---

```{r Plate QC- setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set()
```

## Aim

This code aims to do a plate- level quality control analysis for Luminex
studies through bead counts, Background MFI, and Standard curve
analysis.

### R Markdown

This is an R Markdown document, areas that between the `{r Plate QC-}` frames that
are require manual entries as described in the **bolded text**. When
entries are completed, press the *knit* button at the top of the page.

```{=html}
<!-- *Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>. #When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this with `and`* /
--->
```
```{=html}
<!--
DEVELOPER NOTES
#useful links BSA corrected-- <https://docs.google.com/spreadsheets/d/1kFEW7UqGGvfmOtYQq_AdP3V2w7LwdhDLpTHPmPaJGnM/edit#gid=1434210263>

#TODO: potential transplate normalization based on standards

-->
```
```{r Plate QC- Library loads, include=FALSE}
# No input required
            library(tidyverse)
            library(here)
            library(dplyr)
            library(ggplot2)
            library(gridExtra)
```

#### Dependencies

-   `r R.version.string`
    -   `tidyverse` (v. `r packageVersion("tidyverse")`)
    -   `here` (v. `r packageVersion("here")`)

## Required Inputs

### 1. Confirm working directory:

This is the project folder where the project is found. All folders and
files added to the code will be within this folder. If needed you can
set the working directory using the `setwd()` function.

**Working directory**: `r getwd()`

### 2. Choose file (input required):

Chose the raw plate file from working directory by adding what folder
within (in the quotes). In the example below, the plate csv is in the
`Project/data/raw/luminex/` folder.

### 3. Set minimum bead count:

Set the **minimum bead count** as `min_beadcount`. In this example, the
standard we have set here is `50`. All bead counts \<50 will be
identified.

### 4 Define the `file_path`:

For example, here "Project/data/qc" folder is where the
*PlateName_beadqc_df.csv will be saved*

```{r Plate QC- Required Inputs, echo=TRUE, warning=TRUE}
#Input here is in YAML
    # Set Minimum bead count for analysis
    min_beadcount <- params$min_bead_count
    
    # Chose Output file path
    file_path <- params$file_path
```
# Quality Control

### Bead count per Antigen
  This code assists in check if low bead counts are associated with specific antigens. Note the plot below is not oriented as a 96-well plate given it displays multiple antigens per well. 

```{r Plate QC- Bead count analysis, echo=FALSE, fig.height=17, fig.width=10, warning=FALSE}

# No input required
      lines <- readLines(input_file)
      # Bead count >50
        # create bead_qc dataframe   
        # Find Bead count data 
        #start row: 1 below "DataType: Count" row but not "Per Bead Count"
        start_row <- grep("DataType", lines) # Find rows with "DataType"
        start_row <- start_row[grepl("Count", lines[start_row])] # Filter rows with "Count"
        start_row <- start_row[!grepl("Per Bead", lines[start_row])]  # Filter out rows with "Per Bead"
        
        start_row <- max(start_row) + 1 
        
        #end row: 2 above "Avg Net MFI" row
        end_row <- grep("Avg Net MFI", lines) - 2
        
        # Extract beadqc_df
        if (length(start_row) > 0 & length(end_row) > 0) {
          beadqc_df <- read.csv(text = paste(lines[start_row:end_row], collapse = "\n"))
          
          # Trim beadqc_df to include only columns between "Location" and the column before "Total.Events"
          location_index <- grep("Location", colnames(beadqc_df))
          total_events_index <- grep("Total.Events", colnames(beadqc_df))
          beadqc_df <- beadqc_df[, c(location_index, (location_index + 1):(total_events_index - 1))]
        } else {
          beadqc_df <- NULL
        }
        #Heatmap
             # Convert the dataframe to long format
               beadqc_long <- pivot_longer(beadqc_df, cols = -c(Location, Sample), names_to = "Numeric_Column", values_to = "Value")
                
              # Convert the "Value" column to numeric
                beadqc_long$Value <- as.numeric(beadqc_long$Value)
          
            # Create the title
              title <- paste("Quality Control: Bead count for each antigen",gsub(".csv", "", basename(input_file)))
              
         
           # Create the heatmap
              plot <- ggplot(beadqc_long, aes(x = Numeric_Column, y = factor(Location, levels = rev(unique(beadqc_long$Location))), fill = Value)) +
                geom_tile(color = "black") +
                scale_fill_gradient(low = "red", high = "blue", limits = c(0, max(beadqc_long$Value)), breaks = seq(0, max(beadqc_long$Value), by = 50)) +
                labs(x = "Antigen", y = "Location", title = title) +  # Set the title
                theme_minimal()

      # Export the plot to file_path
      output_file <- file.path(file_path, paste0(tools::file_path_sans_ext(basename(input_file)), "_beadqc.png"))
      ggsave(filename = output_file, plot = plot, width = 10, height = 6, dpi = 300)
       # Print a message indicating the export was successful
                  cat("The bead QC report has been exported to", output_file, "\n")
                  
      #Display plot
              plot
     
```

### Bead Count: per well

This code results in a 96 plate- well schematic indicating wells with low wells. A :ist of wells, sample IDs, and analytes that are less than the minimum bead count set. This file is exported to
`file_path` (chosen above) as *PlateName_beadqc_low_df.csv*. Values in
this list will be `Na` in the Median MFI dataframe. `file_path`:
`r file_path` (this can be edited in the **Bead Count** section)

```{r Plate QC- Low bead count list, echo=FALSE}
# No input required

        # Replace <50 bead as "Low"
        for (col in names(beadqc_df)[sapply(beadqc_df, is.numeric)]) {
          beadqc_df[[col]][beadqc_df[[col]] < min_beadcount] <- "Failed QC (bead)"
        }
        
        # Dataframe of low wells (beadqc_low_df)
        beadqc_low_df <- beadqc_df %>%
          gather(Column, Value, -Location, -Sample) %>%
          filter(Value == "Low") %>%
          select(Location, Sample, Column) %>%
          rename(Antigen = Column) %>%
          mutate(Plate = gsub("\\.csv$", "", basename(input_file)))
        
        # Export filepath + Plate name in csv
        output_file_list <- file.path("data/qc/", 
                                      paste0(tools::file_path_sans_ext(basename(input_file)), "_beadqc_low_df.csv"))
        
        # Export the beadqc_low_df as a CSV file
        write.csv(beadqc_low_df, file = output_file_list, row.names = FALSE)
        
        # Create well schematic
                # Extract row and column indices from Location
                beadqc_low_df$row_col <- gsub(".*,(.*)\\)", "\\1", beadqc_low_df$Location)
                beadqc_low_df$row <- gsub("\\(.*", "", gsub(".*\\)", "", beadqc_low_df$Location))
                beadqc_low_df$col <- gsub(".*\\)", "", gsub("\\(.*", "", beadqc_low_df$Location))
                
                # Create plate layout with row_col column
                plate_layout <- expand.grid(
                  row = LETTERS[1:8],
                  col = as.character(1:12)
                )
                plate_layout$row_col <- paste0(plate_layout$row, plate_layout$col)
                
                # Merge with low well locations to mark low wells
                plate_layout$is_low <- plate_layout$row_col %in% beadqc_low_df$row_col
                
                # Generate the plot
                title <- paste("96-well schematic of Plate: ", gsub(".csv", "", basename(input_file)))
                plate_plot <- ggplot(plate_layout, aes(x = col, y = row, fill = is_low)) +
                  geom_tile(color = "black") +
                  scale_fill_manual(values = c("deepskyblue3", "darkred"), labels = c("Passed", "Low bead count")) +
                  labs(x = "Column", y = "Row", title = title, fill = "Bead Count") +
                  theme_minimal() +
                  theme(axis.text.x = element_text(angle = 0, vjust = 0.5, hjust = 1),
                        axis.text.y = element_text(angle = 0, vjust = 0.5, hjust = 1)) +
                  guides(fill = guide_legend(title = "Bead count QC"))
                
                # Modify the y-axis to have the top row as "A" and the bottom row as "H"
                plate_plot <- plate_plot + scale_y_discrete(limits = rev(levels(factor(plate_layout$row))))
                
       # Display the plot
          plate_plot

        # Display list
          selected_columns <- beadqc_low_df %>% select(Location, Sample, Antigen, Plate)
        selected_columns
        
        # Print a message indicating the export was successful
        cat("The bead QC list has been exported to", output_file_list, "\n", "This file will be added to in data/qc/qc_compile.csv")
```

## QC of median MFI data

This extracts the median MFI data, with all well-analyte combinations
\<50 beads/well replaced with *NA*. It completes the BSA MFI subtraction
as well

*note: negative values are kept*

```{r Plate QC- Median MFI w/ low bead count removal, warning=FALSE, include=FALSE}
#No input required
      # Median MFI ----
            # results_df: File Extraction, initial triming, BSA subtraction for Median MFI data ---- 
            # Median MFI dataframe: Below "Median" and two above "Net MFI"    
                  # Find the row index containing the word "Median"
                  median_row_index <- grep("Median", lines)
                  
                  # Find the row index containing the word "Net MFI"
                  net_mfi_row_index <- grep("Net MFI", lines)
                  
                  # Find the row index of two rows above "Net MFI"
                  net_mfi_row_index <- net_mfi_row_index - 2
                  
                  # Extract data between "Median" and two rows above "Net MFI"
                  data_lines <- lines[(median_row_index + 1):net_mfi_row_index]
              # Create a data frame
                results_df <- read.csv(text = paste(data_lines, collapse = "\n"), na.strings = "")
            
            # Remove low bead values as NA, using beadqc_low_df
                  for (i in 1:nrow(beadqc_low_df)) {
                    # Extract information from beadqc_low_df
                    location <- beadqc_low_df$Location[i]
                    column <- beadqc_low_df$Column[i]
                    sample <- beadqc_low_df$Sample[i]
                    
                    # Find the row index in results_df where Location and Sample match
                    row_index <- which(results_df$Location == location & results_df$Sample == sample)
                    
                    # Remove value in specified column for the found row index
                    results_df[row_index, column] <- NA
                  }
                  
            # Creation of results_df: Filter out columns between "Location" and "Total.Events"
            location_index <- grep("Location", colnames(results_df))
            total_events_index <- grep("Total.Events", colnames(results_df))
            columns_to_keep <- (location_index + 1):(total_events_index - 1)
            
            results_df <- results_df[, columns_to_keep]
            
        # BSA Subtraction
           # Assuming BSA column index is known
            bsa_index <- grep("BSA", colnames(results_df))
            
                  # Store the BSA column separately
                  bsa_values <- results_df[, bsa_index]
                  
                  # Identify numerical columns excluding BSA
                  nonBSA_numerical_columns <- sapply(results_df[, -bsa_index], is.numeric)
            
            # Subtract BSA from numerical columns
            results_df[, nonBSA_numerical_columns] <- results_df[, nonBSA_numerical_columns] - bsa_values
              
                  # Reinsert the BSA column
                  results_df[, bsa_index] <- bsa_values
```

### Background MFI

This code averages the median MFI values for all background and
non-background samples. This requires all Background samples to have
"Background" within the characters in the `Sample` column

```{r Plate QC- Background Median MFI plot, echo=FALSE, fig.width=8, fig.height=6}
# No input required
        # Analytes: Get the names of numerical columns
          analytes <- names(results_df)[sapply(results_df, is.numeric)]
        
        # Filter rows with "Background" and without "Background" in Sample column
            background_rows <- results_df %>%
              filter(grepl("^Background", Sample, ignore.case = TRUE))
            non_background_rows <- results_df %>%
              filter(!grepl("^Background", Sample, ignore.case = TRUE))
        
        # Calculate averaged MFI
            background_averages <- background_rows %>%
              summarise(across(all_of(analytes), ~ mean(., na.rm = TRUE)))
            non_background_averages <- non_background_rows %>%
              summarise(across(all_of(analytes), ~ mean(., na.rm = TRUE)))
        
        # Combine average frames
            background_averages <- background_averages %>%
              pivot_longer(cols = everything(), names_to = "Column", values_to = "Average", names_prefix = "background_")
            background_averages$Type <- "Background"
            
            non_background_averages <- non_background_averages %>%
              pivot_longer(cols = everything(), names_to = "Column", values_to = "Average", names_prefix = "non_background_")
            non_background_averages$Type <- "Non-Background"
            
            averages_combined <- rbind(background_averages, non_background_averages)
        
        # Bar graph
          # Create Title
          title <- paste("Background analysis for", gsub(".csv", "", basename(input_file)))
          
          # Create plot
          ggplot(averages_combined, aes(x = Column, y = Average, fill = Type)) +
            geom_bar(stat = "identity", position = "dodge") +
            scale_fill_manual(values = c("darkslategrey", "cornflowerblue")) + # Set custom colors
            labs(title = title,
                 x = "Analyte", y = "Averaged Median MFI") +
            theme_minimal()
          
```

### Standard curve

This code will attempt to create standard curves. This requires the
samples have "Standard" within the characters in the `Sample` column.
This will extraction `Dilution_Factor` as the number within the name (x
-1).

For example: \*Standard 2\* will have a `Dilution_factor` of -2

This code will run for all `analyte`

```{r Plate QC- plate standard plots, echo=FALSE, warning=FALSE, fig.width=8, fig.height=14}
# Initialize plate_qc as an empty dataframe
plate_qc <- data.frame(Analyte = character(), R_squared = numeric())

# Function to calculate correlation and R-squared
calculate_correlation <- function(df) {
  lm_model <- lm(Log10_MFI ~ Dilution_Factor, data = df)
  correlation <- cor(df$Log10_MFI, df$Dilution_Factor)
  r_squared <- summary(lm_model)$r.squared
  return(list(correlation = correlation, r_squared = r_squared))
}

# Step 1: Filter standard samples
standards_df <- results_df %>%
  filter(str_detect(Sample, "Standard"))

# Step 2: Extract dilution factor
standards_df <- standards_df %>%
  mutate(Dilution_Factor = -as.numeric(str_extract(Sample, "\\d+")))

# Step 3: Identify analyte columns
analyte_cols <- names(standards_df)[sapply(standards_df, is.numeric) & names(standards_df) != "Dilution_Factor"]

# Step 4: Prepare data for plotting
melted_df <- standards_df %>%
  select(-Sample) %>%
  pivot_longer(cols = all_of(analyte_cols), 
               names_to = "Analyte", 
               values_to = "MFI") %>%
  mutate(Log10_MFI = log10(MFI + 1))  # Adding 1 to avoid log(0)

# Step 5: Create standard curves for each analyte
plots_list <- lapply(unique(melted_df$Analyte), function(analyte) {
  # Filter data for the current analyte and remove NA/infinite values
  analyte_df <- filter(melted_df, Analyte == analyte & !is.na(Log10_MFI) & !is.infinite(Log10_MFI))
  
  # Check if analyte_df is empty after filtering
  if (nrow(analyte_df) == 0) {
    message(paste("No valid data for analyte:", analyte))
    return(NULL)
  }
  
  # Create plot
  plot <- ggplot(analyte_df, aes(x = Dilution_Factor, y = Log10_MFI)) +
    geom_point() +
    geom_smooth(method = "lm", se = FALSE, color = "blue") + # Add line of best fit
    labs(title = paste("Standard curve for", analyte),
         x = "Dilution Factor",
         y = "Log10(MFI)") +
    theme_minimal()
  
  # Calculate correlation and R-squared
  correlation_r_squared <- calculate_correlation(analyte_df)
  
  # Add R-squared value to the plot annotation
  plot <- plot + 
    annotate("text", x = Inf, y = -Inf, 
             label = paste("R^2 =", round(correlation_r_squared$r_squared, 2)), 
             hjust = 1, vjust = 0)
  
  # Append analyte and R-squared value to plate_qc data frame
  plate_qc <<- bind_rows(plate_qc, data.frame(Analyte = analyte, R_squared = correlation_r_squared$r_squared))
  
  return(plot)
})

# Combine all plots into a single object
combined_plots <- do.call(gridExtra::grid.arrange, c(plots_list, ncol = 2))

# Print combined plots
print(combined_plots)



```

# QC- Plate standard curve
The minimum R squared value set for this study is `r min_Rsquared`. In order to pass quality control for appropriate standard curve response, at least one analyte requires a minimum Rsquared > than that value.

```{r Plate QC- R squared, warning=FALSE}
min_Rsquared <- as.numeric(params$min_Rsquared)

# Remove duplicate rows from plate_qc
plate_qc <- plate_qc %>%
  distinct()

# Create min_Rsq column (coercing to logical)
plate_qc$min_Rsq <- plate_qc$R_squared > min_Rsquared
plate_qc$min_Rsq <- as.logical(plate_qc$min_Rsq)


# View plate_qc
plate_qc

# Check if any analyte meets the preset minimum R squared value
if (any(plate_qc$min_Rsq)) {
  # If at least one analyte meets the criteria
  print("This plate has passed plate-level quality control for standard curve linearity.")
  print("At least one analyte meets the criteria for the preset minimum R-squared (see YAML).")
  print ("Median MFI from this plate will be included in the compiled study dataframe")
} else {
  # If no analytes meet the criteria
  print("This plate has failed plate-level QC for standard curves.")
  print("No analytes met the preset minimum R-squared.")
  print("All MFI values from this plate will display as `Failed Plate QC`")
}



```