---
title: "Luminex Compilation"
author: "Sahal Thahir & Jeff Bailey"
date: "2024-04-12"
output:
  pdf_document: default
editor_options: 
  markdown: 
    wrap: 72
---


```{r setup, include=FALSE}


knitr::opts_chunk$set(echo = FALSE)
knitr::opts_knit$set()
print ("working directory is: ")
getwd()
```
# Aim

This code allows a user to compile luminex xPONENT output for an overall experiment across multiple conditions and plates. This document may be best readable in `visual` mode (top left). Follow the numerical steps below, all code chunks with `#No input required` can be skipped. 

### R Markdown

This is an R Markdown document. See Code for details.

```{=html}
# no input required
    <!-- *Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>. #When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this with `and`* /
    --->
    ```
    ```{=html}
    <!--
    DEVELOPER NOTES
    #useful links BSA corrected-- <https://docs.google.com/spreadsheets/d/1kFEW7UqGGvfmOtYQq_AdP3V2w7LwdhDLpTHPmPaJGnM/edit#gid=1434210263>
    
    #TODO: potential transplate normalization based on standards

-->
```
# Dependencies 
### R Dependencies 
(*No input required*)
-   `r R.version.string`

    -   `tidyverse` (v. `r packageVersion("tidyverse")`)
    
    -   `here` (v. `r packageVersion("here")`)
    
    *use `install.packages("package name")` if not previously installed.*  

```{r R Dependencies, include=FALSE}
# No input required
  library(tidyverse)
  library(here)
```
### Data dependencies
*Plate names*:This code extracts metadata based on the plate name. Plate file nomenclature should be include Plate condition (ex: IgG1, Ig3, FcR2a, etc.), Plate # (if same condition), date, and an experimenter as 


  File name: *CONDITION_PLATE#\_YYYY-MM-DD-INITIALS.csv*
  
  *e.g. IgG1_PLATE1_2024-03-07_JAB.csv, IgGTotal_PLATE1_23.10.25_AM.csv*

# 1. Set directory parameters

This code chunk specifies the project name and internal file paths for the raw data files, 
  remember the working directory for this project is *`r getwd()`*
  
  `projectname`: insert study name in quotes
    
  `rawdir`: raw data file directory (within the working directory)
  
  `platelist`: is the plates 
  
  `samplelistfile`: is the sample data file. This contains the attributes of the Sample outside of the Luminex csv. 

```{r echo=TRUE}
#set default variables
projectname ="BLTEST"
rawdir = "data/EBL_RawData"  #<- the directory with the 'raw' exported xPONENT files appropriately named
platelist = c("PLATE1","PLATE2") #the plates to include in the analysis 
#note conditions can be selected but you can simply limit them by moving files into another directory
samplelistfile=c("data/SampleList_metadata.tsv")  #this is the mappoing of the PlateIDs (#s) --> SampleIDs
```

# 2. Data cleaning 
(*input optional*)

All names will automatically changed to UPPERCASE and spaces will be changed to dashes (-)

## Fix inconsistencies
### Make text consistent:
Using the `~` function, this will replace text within the files to match what you define to ensure consistency. Note: ` "REPLACEMENT"~ "RAW"`

### Delete samples:
Add a `"Sample"` if you desire to remove a sample name from the dataframe. Note: this does not change the raw file. 

```{r Data cleaning, echo=FALSE}
# Input optional
  # 1. Fix names (optional)
    namefixes = c(
      "BLANK" ~ "BACKGROUND0"  ,
      "1832" ~ "HC-189K",
      "534." ~ "MBL-179",
      "589*" ~ "BL736",
      "MALE-EBV-NEG" ~ "EBV-MALE-NEG",
      "FEMALE-EBV-NEG" ~ "EBV-FEMALE-NEG",
      "AF-S1" ~ "AF-MIX-S1",
      "AF-S2" ~ "AF-MIX-S2",
      "AF-S3" ~ "AF-MIX-S3",
      "AF-S4" ~ "AF-MIX-S4",
      "AF-S5" ~ "AF-MIX-S5",
      "AF-S6" ~ "AF-MIX-S6",
      "AF-S7" ~ "AF-MIX-S7",
      "POST-VAC-S6"~ "POST-VACC-S6"
    ) 

# 2. Remove samples "optional"
deletesamples = c(
  "479",
  "CSP-OLD-BEAD-MIX-S1",
  "CSP-OLD-BEAD-MIX-S2",
  "CSP-OLD-BEAD-MIX-S3",
  "CSP-OLD-BEAD-MIX-S4",
  "CSP-OLD-BEAD-MIX-S5",
  "CSP-OLD-BEAD-MIX-S6",
  "CSP-OLD-BEAD-MIX-S7"
)


```

## Read Sample list

The `samplelistfile` input in #1 will be read below. The sample list must have PlateID -that can map to SampleID columns to allow for proper mapping. If you have no renaming to do (plates all contain SampleID already) then just use file with these columns but no rows.

```{r Load samples, echo=FALSE, warning=FALSE}
# No input required
    #load the sample list
    samplelist=read_tsv(samplelistfile, col_types="c")
    print (samplelist)
    
    
    #If renaming required (SampleID in name)
    if ( !("PlateID" %in% names(samplelist) & "SampleID" %in% names(samplelist))  ) {
      cat ("Column Names", names(samplelist))
      stop ("Either PlateID or SampleID is missing from samplelist file!")
    }

```

```{r output, echo=FALSE}
# No input required
  outputdir=paste0(projectname,"_compiled_output")
  if (!file.exists(outputdir) ) { dir.create(outputdir) }
  unlink( paste0( outputdir,"/*sv"))  #remove all csv and tsv files
```

# 3. Processing Plate data 
(*No input required*)

This chunk does the main work. It will create the merged tsvs into the compiled output directory as well as save individual files and compiled plates for potential inspection.

### Explanation
### 1. Initialization:
        ftib and ptib are initialized as NULL. This will hold the full compiled data and the data for a single plate, respectively.
### 2. Outer Loop (Plates):
        Loops through each plate in platelist.
        Retrieves a list of raw files associated with the current plate.
        Prints the plate being processed and the list of raw files.
### 3. Inner Loop (within each Plate):
        Loops through each raw file associated with the current plate.
        Splits the raw file name to extract the secondary condition.
        Reads the file, extracts data based on specified conditions, and calculates the median.
        Writes the median to a temporary file, reads it as a tibble, and removes the temporary file.       Processes the data:
            Adjusts columns based on conditions.
            Renames columns.
            Adds plate identifier and other columns.
            Checks if SampleID maps to PlateID and makes adjustments.
            Cleans up sample names and counts occurrences.
        Writes the processed data to a TSV file.

### 4. Combining Data across Files within each Plate:
        Joins the processed data across conditions/antibodies for a single plate (full join).
        If ptib is NULL, it assigns the current plate data to ptib, otherwise it performs a full join with existing ptib.

### 5. Printing and Writing Compiled Plate Data:
        Prints the compiled plate data.
        Writes the compiled plate data to a TSV file.

### 6. Combining Data across Plates:
        Joins the compiled plate data across plates (binding rows).
        If ftib is NULL, it assigns the current plate data to ftib, otherwise it appends the current plate data to ftib.

### 7. Writing Full Compiled Data:
        Writes the full compiled data (across all plates) to a TSV file.

```{r echo=FALSE, warning=FALSE}
# No input required
     #this code will extract plate data 
      ftib<-NULL
    #loop through the individual plates
    for (plate in platelist) {
      rawfilelist<-list.files(rawdir, plate)
      cat ("loading ",plate, rawfilelist, "\n\n")
      #process all the different conditions/secondary treatments for a given plate of samples#
      ptib<-NULL
      sampleids<-tibble()
      for (rawfile in rawfilelist) {
        secondary = strsplit(rawfile,"_")  #TODO: rename to condition?
        secondaryname <- secondary[[1]][1]
        fpath <-  paste (rawdir, rawfile, sep="/") 
        filetext<-readLines(fpath) #using a raw read of lines due to ragged nature of file
        datastart <-grep ("DataType:", filetext)  #find instances of DataType  
        #this finds the median ( could go after other metrics as well)
        rownum = datastart[2]-datastart[1] 
        median<- (filetext[seq(datastart[1]+1,datastart[2]-2)])
        ##write to a temporary file- 
        #TODO: save temporary file as a raw format table in output if need
        write_lines(median,"TeMp")
        tib<-  read_csv ("TeMp", show_col_types=FALSE)
        file.remove("TeMp")
        
        #process the individual plate tibble 
        tib <- tib %>% 
          select(-c("Total Events")) %>%
          mutate( across(.cols =-c("Location","Sample","BSA") , ~ .x -tib$BSA )) %>%
          rename_with(.fn = ~ paste0(secondaryname ,"_", .x) )  %>%
          rename_with(.cols=1, ~"Location" ) %>%
          rename_with(.cols=2, ~"Sample") %>%
          add_column(Plate=plate, .before= 1)
        ### TODO: could add renaming specific beads if errors ever occurred ???
        #clean names and check to see if PlateID maps to SampleID
        tib$lookup <-samplelist$SampleID[match ( tib$Sample,samplelist$PlateID) ]
        tib <- tib %>%
           mutate(Sample = case_when(
                  !is.na(lookup) ~ lookup, .default = Sample
           ))   %>%
           mutate(Sample = toupper(gsub('\\s+', '-', Sample))) %>%
           mutate(Sample = case_match(
             Sample, !!!namefixes, .default=Sample)
           ) %>%
           select (-c(lookup, Location)) %>%
           filter(! Sample %in% deletesamples )
        ### names are often redundant so count them within a given plate ###
        occurence=c()
        for (i in 1:length(tib$Sample) ) {
          occurence[i]= length( which(tib$Sample[1:i] == tib$Sample[i]) )
        }
        tib<-tib %>% 
          add_column(Inplatecount=occurence, .before= 2)  
        write_tsv(tib, paste0(outputdir,"/",secondaryname,"_",plate,"clean.tsv"))
    
        ## join across conditions/antibodies across a plate  (fulljoin)  
        if ( is.null(ptib)) {
          ptib <-tib
        } else {
          ptib<- full_join(ptib,tib,join_by(Plate==Plate,
                              Sample==Sample, Inplatecount== Inplatecount))
        }
      }
      print (ptib)
      write_tsv(ptib, paste0(outputdir,"/",projectname,"_",plate,"_compiled.tsv"))
    
      if (is.null(ftib)) {
         ftib<-ptib   
      } else {
          ftib<- dplyr::bind_rows(ftib, ptib ) 
      }
      
    }
    write_tsv(ftib, paste0(outputdir, "/", projectname, "_", "fullcompile.tsv"))
```

The end ...
